{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fashion_YOLOv4_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6XKoOvJnODy"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from skimage.transform import resize\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftA0xj1rKR1S",
        "outputId": "9fd115e7-48fd-48da-cf29-39f8f6a160c4"
      },
      "source": [
        "# img_path = \"drive/My Drive/data/test/\"\n",
        "path = \"drive/MyDrive/Colab Notebooks/fashion_yolo/label.csv\"\n",
        "classes = []\n",
        "box_info = pd.read_csv(path, sep=\",\", encoding=\"CP950\")\n",
        "obj_name = box_info[\"obj_name\"].unique()\n",
        "for i in range(len(obj_name)):\n",
        "  box_info.loc[box_info[\"obj_name\"] == obj_name[i], \"obj_name\"] = i\n",
        "  classes.append(obj_name[i])\n",
        "\n",
        "box_info.loc[box_info[\"col_left\"] < 0, \"col_left\"] = 0\n",
        "box_info.loc[box_info[\"col_left\"] > 1, \"col_left\"] = 1\n",
        "\n",
        "box_info.loc[box_info[\"col_right\"] < 0, \"col_right\"] = 0\n",
        "box_info.loc[box_info[\"col_right\"] > 1, \"col_right\"] = 1\n",
        "\n",
        "box_info.loc[box_info[\"row_bot\"] < 0, \"row_bot\"] = 0\n",
        "box_info.loc[box_info[\"row_bot\"] > 1, \"row_bot\"] = 1\n",
        "\n",
        "box_info.loc[box_info[\"row_top\"] < 0, \"row_top\"] = 0\n",
        "box_info.loc[box_info[\"row_top\"] > 1, \"row_top\"] = 1\n",
        "\n",
        "box_info\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['person', 'upper-body', 'lower-body', 'full-body', 'face']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3_CgCyuzbFrx"
      },
      "source": [
        "#---------------------------------------------------#\n",
        "#   获得类和先验框\n",
        "#---------------------------------------------------#\n",
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape([-1,3,2])[::-1,:,:]\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OO6pXq3fGVU",
        "outputId": "13ec0889-4399-4d74-dcc8-40b39d6427b1"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        " #-------------------------------#\n",
        "#   输入的shape大小\n",
        "#   显存比较小可以使用416x416\n",
        "#   显存比较大可以使用608x608\n",
        "#-------------------------------#\n",
        "input_shape = (416,416)\n",
        "#-------------------------------#\n",
        "#   tricks的使用设置\n",
        "#-------------------------------#\n",
        "Cosine_lr = False\n",
        "mosaic = True\n",
        "# 用于设定是否使用cuda\n",
        "Cuda = True\n",
        "smoooth_label = 0\n",
        "#-------------------------------#\n",
        "#   Dataloder的使用\n",
        "#-------------------------------#\n",
        "Use_Data_Loader = True\n",
        "img_path = 'drive/MyDrive/Colab Notebooks/fashion_yolo/img/'\n",
        "#-------------------------------#\n",
        "#   获得先验框和类\n",
        "#-------------------------------#\n",
        "anchors_path = 'drive/MyDrive/data/coco/VOCdevkit/VOC2007/model_data/yolo_anchors.txt'\n",
        "#classes_path = 'drive/MyDrive/data/coco/VOCdevkit/VOC2007/model_data/voc_classes.txt'\n",
        "class_names = classes\n",
        "anchors = get_anchors(anchors_path)\n",
        "num_classes = len(class_names)\n",
        "print(class_names)\n",
        "print(anchors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['person', 'upper-body', 'lower-body', 'full-body', 'face']\n",
            "[[[142. 110.]\n",
            "  [192. 243.]\n",
            "  [459. 401.]]\n",
            "\n",
            " [[ 36.  75.]\n",
            "  [ 76.  55.]\n",
            "  [ 72. 146.]]\n",
            "\n",
            " [[ 12.  16.]\n",
            "  [ 19.  36.]\n",
            "  [ 40.  28.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "70qt-tDfgQDW"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "\n",
        "#-------------------------------------------------#\n",
        "#   MISH激活函数\n",
        "#-------------------------------------------------#\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mish, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "#-------------------------------------------------#\n",
        "#   卷积块\n",
        "#   CONV+BATCHNORM+MISH\n",
        "#-------------------------------------------------#\n",
        "class BasicConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
        "        super(BasicConv, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, kernel_size//2, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = Mish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   CSPdarknet的结构块的组成部分\n",
        "#   内部堆叠的残差块\n",
        "#---------------------------------------------------#\n",
        "class Resblock(nn.Module):\n",
        "    def __init__(self, channels, hidden_channels=None, residual_activation=nn.Identity()):\n",
        "        super(Resblock, self).__init__()\n",
        "\n",
        "        if hidden_channels is None:\n",
        "            hidden_channels = channels\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            BasicConv(channels, hidden_channels, 1),\n",
        "            BasicConv(hidden_channels, channels, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   CSPdarknet的结构块\n",
        "#   存在一个大残差边\n",
        "#   这个大残差边绕过了很多的残差结构\n",
        "#---------------------------------------------------#\n",
        "class Resblock_body(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, first):\n",
        "        super(Resblock_body, self).__init__()\n",
        "\n",
        "        self.downsample_conv = BasicConv(in_channels, out_channels, 3, stride=2)\n",
        "\n",
        "        if first:\n",
        "            self.split_conv0 = BasicConv(out_channels, out_channels, 1)\n",
        "            self.split_conv1 = BasicConv(out_channels, out_channels, 1)  \n",
        "            self.blocks_conv = nn.Sequential(\n",
        "                Resblock(channels=out_channels, hidden_channels=out_channels//2),\n",
        "                BasicConv(out_channels, out_channels, 1)\n",
        "            )\n",
        "            self.concat_conv = BasicConv(out_channels*2, out_channels, 1)\n",
        "        else:\n",
        "            self.split_conv0 = BasicConv(out_channels, out_channels//2, 1)\n",
        "            self.split_conv1 = BasicConv(out_channels, out_channels//2, 1)\n",
        "\n",
        "            self.blocks_conv = nn.Sequential(\n",
        "                *[Resblock(out_channels//2) for _ in range(num_blocks)],\n",
        "                BasicConv(out_channels//2, out_channels//2, 1)\n",
        "            )\n",
        "            self.concat_conv = BasicConv(out_channels, out_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample_conv(x)\n",
        "\n",
        "        x0 = self.split_conv0(x)\n",
        "\n",
        "        x1 = self.split_conv1(x)\n",
        "        x1 = self.blocks_conv(x1)\n",
        "\n",
        "        x = torch.cat([x1, x0], dim=1)\n",
        "        x = self.concat_conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class CSPDarkNet(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super(CSPDarkNet, self).__init__()\n",
        "        self.inplanes = 32\n",
        "        self.conv1 = BasicConv(3, self.inplanes, kernel_size=3, stride=1)\n",
        "        self.feature_channels = [64, 128, 256, 512, 1024]\n",
        "\n",
        "        self.stages = nn.ModuleList([\n",
        "            Resblock_body(self.inplanes, self.feature_channels[0], layers[0], first=True),\n",
        "            Resblock_body(self.feature_channels[0], self.feature_channels[1], layers[1], first=False),\n",
        "            Resblock_body(self.feature_channels[1], self.feature_channels[2], layers[2], first=False),\n",
        "            Resblock_body(self.feature_channels[2], self.feature_channels[3], layers[3], first=False),\n",
        "            Resblock_body(self.feature_channels[3], self.feature_channels[4], layers[4], first=False)\n",
        "        ])\n",
        "\n",
        "        self.num_features = 1\n",
        "        # 进行权值初始化\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        x = self.stages[0](x)\n",
        "        x = self.stages[1](x)\n",
        "        out3 = self.stages[2](x)\n",
        "        out4 = self.stages[3](out3)\n",
        "        out5 = self.stages[4](out4)\n",
        "\n",
        "        return out3, out4, out5\n",
        "\n",
        "def darknet53(pretrained, **kwargs):\n",
        "    model = CSPDarkNet([1, 2, 8, 8, 4])\n",
        "    if pretrained:\n",
        "        if isinstance(pretrained, str):\n",
        "            model.load_state_dict(torch.load(pretrained))\n",
        "        else:\n",
        "            raise Exception(\"darknet request a pretrained path. got [{}]\".format(pretrained))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5XvfTGKcgUNK"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "\n",
        "def conv2d(filter_in, filter_out, kernel_size, stride=1):\n",
        "    pad = (kernel_size - 1) // 2 if kernel_size else 0\n",
        "    return nn.Sequential(OrderedDict([\n",
        "        (\"conv\", nn.Conv2d(filter_in, filter_out, kernel_size=kernel_size, stride=stride, padding=pad, bias=False)),\n",
        "        (\"bn\", nn.BatchNorm2d(filter_out)),\n",
        "        (\"relu\", nn.LeakyReLU(0.1)),\n",
        "    ]))\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   SPP结构，利用不同大小的池化核进行池化\n",
        "#   池化后堆叠\n",
        "#---------------------------------------------------#\n",
        "class SpatialPyramidPooling(nn.Module):\n",
        "    def __init__(self, pool_sizes=[5, 9, 13]):\n",
        "        super(SpatialPyramidPooling, self).__init__()\n",
        "\n",
        "        self.maxpools = nn.ModuleList([nn.MaxPool2d(pool_size, 1, pool_size//2) for pool_size in pool_sizes])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = [maxpool(x) for maxpool in self.maxpools[::-1]]\n",
        "        features = torch.cat(features + [x], dim=1)\n",
        "\n",
        "        return features\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   卷积 + 上采样\n",
        "#---------------------------------------------------#\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Upsample, self).__init__()\n",
        "\n",
        "        self.upsample = nn.Sequential(\n",
        "            conv2d(in_channels, out_channels, 1),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        )\n",
        "\n",
        "    def forward(self, x,):\n",
        "        x = self.upsample(x)\n",
        "        return x\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   三次卷积块\n",
        "#---------------------------------------------------#\n",
        "def make_three_conv(filters_list, in_filters):\n",
        "    m = nn.Sequential(\n",
        "        conv2d(in_filters, filters_list[0], 1),\n",
        "        conv2d(filters_list[0], filters_list[1], 3),\n",
        "        conv2d(filters_list[1], filters_list[0], 1),\n",
        "    )\n",
        "    return m\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   五次卷积块\n",
        "#---------------------------------------------------#\n",
        "def make_five_conv(filters_list, in_filters):\n",
        "    m = nn.Sequential(\n",
        "        conv2d(in_filters, filters_list[0], 1),\n",
        "        conv2d(filters_list[0], filters_list[1], 3),\n",
        "        conv2d(filters_list[1], filters_list[0], 1),\n",
        "        conv2d(filters_list[0], filters_list[1], 3),\n",
        "        conv2d(filters_list[1], filters_list[0], 1),\n",
        "    )\n",
        "    return m\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   最后获得yolov4的输出\n",
        "#---------------------------------------------------#\n",
        "def yolo_head(filters_list, in_filters):\n",
        "    m = nn.Sequential(\n",
        "        conv2d(in_filters, filters_list[0], 3),\n",
        "        nn.Conv2d(filters_list[0], filters_list[1], 1),\n",
        "    )\n",
        "    return m\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   yolo_body\n",
        "#---------------------------------------------------#\n",
        "class YoloBody(nn.Module):\n",
        "    def __init__(self, num_anchors, num_classes):\n",
        "        super(YoloBody, self).__init__()\n",
        "        #  backbone\n",
        "        self.backbone = darknet53(None)\n",
        "\n",
        "        self.conv1 = make_three_conv([512,1024],1024)\n",
        "        self.SPP = SpatialPyramidPooling()\n",
        "        self.conv2 = make_three_conv([512,1024],2048)\n",
        "\n",
        "        self.upsample1 = Upsample(512,256)\n",
        "        self.conv_for_P4 = conv2d(512,256,1)\n",
        "        self.make_five_conv1 = make_five_conv([256, 512],512)\n",
        "\n",
        "        self.upsample2 = Upsample(256,128)\n",
        "        self.conv_for_P3 = conv2d(256,128,1)\n",
        "        self.make_five_conv2 = make_five_conv([128, 256],256)\n",
        "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
        "        # 4+1+num_classes\n",
        "        final_out_filter2 = num_anchors * (5 + num_classes)\n",
        "        self.yolo_head3 = yolo_head([256, final_out_filter2],128)\n",
        "\n",
        "        self.down_sample1 = conv2d(128,256,3,stride=2)\n",
        "        self.make_five_conv3 = make_five_conv([256, 512],512)\n",
        "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
        "        final_out_filter1 =  num_anchors * (5 + num_classes)\n",
        "        self.yolo_head2 = yolo_head([512, final_out_filter1],256)\n",
        "\n",
        "\n",
        "        self.down_sample2 = conv2d(256,512,3,stride=2)\n",
        "        self.make_five_conv4 = make_five_conv([512, 1024],1024)\n",
        "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
        "        final_out_filter0 =  num_anchors * (5 + num_classes)\n",
        "        self.yolo_head1 = yolo_head([1024, final_out_filter0],512)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #  backbone\n",
        "        x2, x1, x0 = self.backbone(x)\n",
        "\n",
        "        P5 = self.conv1(x0)\n",
        "        P5 = self.SPP(P5)\n",
        "        P5 = self.conv2(P5)\n",
        "\n",
        "        P5_upsample = self.upsample1(P5)\n",
        "        P4 = self.conv_for_P4(x1)\n",
        "        P4 = torch.cat([P4,P5_upsample],axis=1)\n",
        "        P4 = self.make_five_conv1(P4)\n",
        "\n",
        "        P4_upsample = self.upsample2(P4)\n",
        "        P3 = self.conv_for_P3(x2)\n",
        "        P3 = torch.cat([P3,P4_upsample],axis=1)\n",
        "        P3 = self.make_five_conv2(P3)\n",
        "\n",
        "        P3_downsample = self.down_sample1(P3)\n",
        "        P4 = torch.cat([P3_downsample,P4],axis=1)\n",
        "        P4 = self.make_five_conv3(P4)\n",
        "\n",
        "        P4_downsample = self.down_sample2(P4)\n",
        "        P5 = torch.cat([P4_downsample,P5],axis=1)\n",
        "        P5 = self.make_five_conv4(P5)\n",
        "\n",
        "        out2 = self.yolo_head3(P3)\n",
        "        out1 = self.yolo_head2(P4)\n",
        "        out0 = self.yolo_head1(P5)\n",
        "\n",
        "        return out0, out1, out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hernhVJ1gX1L",
        "outputId": "1bbb6275-af30-4c2e-8fd2-5c0ee76134af"
      },
      "source": [
        "# 创建模型\n",
        "model = YoloBody(len(anchors[0]),num_classes)\n",
        "#-------------------------------------------#\n",
        "#   权值文件的下载请看README\n",
        "#-------------------------------------------#\n",
        "model_path = \"drive/MyDrive/data/coco/VOCdevkit/VOC2007/model_data/yolo4_weights.pth\"\n",
        "# 加快模型训练的效率\n",
        "print('Loading weights into state dict...')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_dict = model.state_dict()\n",
        "pretrained_dict = torch.load(model_path, map_location=device)\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) ==  np.shape(v)}\n",
        "model_dict.update(pretrained_dict)\n",
        "model.load_state_dict(model_dict)\n",
        "print('Finished!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights into state dict...\n",
            "Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nVpcuvFxgbQD",
        "outputId": "f43b6070-8257-4d87-b847-7fd959c54bdb"
      },
      "source": [
        "net = model.train()\n",
        "\n",
        "if Cuda:\n",
        "    net = torch.nn.DataParallel(model)\n",
        "    cudnn.benchmark = True\n",
        "    net = net.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e3e226952dae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iOZRUL2fhUrj"
      },
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torchvision.ops import nms\n",
        "\n",
        "class DecodeBox(nn.Module):\n",
        "    def __init__(self, anchors, num_classes, img_size):\n",
        "        super(DecodeBox, self).__init__()\n",
        "        self.anchors = anchors\n",
        "        self.num_anchors = len(anchors)\n",
        "        self.num_classes = num_classes\n",
        "        self.bbox_attrs = 5 + num_classes\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input为bs,3*(1+4+num_classes),13,13\n",
        "\n",
        "        # 一共多少张图片\n",
        "        batch_size = input.size(0)\n",
        "        # 13，13\n",
        "        input_height = input.size(2)\n",
        "        input_width = input.size(3)\n",
        "\n",
        "        # 计算步长\n",
        "        # 每一个特征点对应原来的图片上多少个像素点\n",
        "        # 如果特征层为13x13的话，一个特征点就对应原来的图片上的32个像素点\n",
        "        # 416/13 = 32\n",
        "        stride_h = self.img_size[1] / input_height\n",
        "        stride_w = self.img_size[0] / input_width\n",
        "\n",
        "        # 把先验框的尺寸调整成特征层大小的形式\n",
        "        # 计算出先验框在特征层上对应的宽高\n",
        "        scaled_anchors = [(anchor_width / stride_w, anchor_height / stride_h) for anchor_width, anchor_height in self.anchors]\n",
        "\n",
        "        # bs,3*(5+num_classes),13,13 -> bs,3,13,13,(5+num_classes)\n",
        "        prediction = input.view(batch_size, self.num_anchors,\n",
        "                                self.bbox_attrs, input_height, input_width).permute(0, 1, 3, 4, 2).contiguous()\n",
        "\n",
        "        # 先验框的中心位置的调整参数\n",
        "        x = torch.sigmoid(prediction[..., 0])  \n",
        "        y = torch.sigmoid(prediction[..., 1])\n",
        "        # 先验框的宽高调整参数\n",
        "        w = prediction[..., 2]  # Width\n",
        "        h = prediction[..., 3]  # Height\n",
        "\n",
        "        # 获得置信度，是否有物体\n",
        "        conf = torch.sigmoid(prediction[..., 4])\n",
        "        # 种类置信度\n",
        "        pred_cls = torch.sigmoid(prediction[..., 5:])  # Cls pred.\n",
        "\n",
        "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
        "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
        "\n",
        "        # 生成网格，先验框中心，网格左上角 batch_size,3,13,13\n",
        "        grid_x = torch.linspace(0, input_width - 1, input_width).repeat(input_width, 1).repeat(\n",
        "            batch_size * self.num_anchors, 1, 1).view(x.shape).type(FloatTensor)\n",
        "        grid_y = torch.linspace(0, input_height - 1, input_height).repeat(input_height, 1).t().repeat(\n",
        "            batch_size * self.num_anchors, 1, 1).view(y.shape).type(FloatTensor)\n",
        "\n",
        "        # 生成先验框的宽高\n",
        "        anchor_w = FloatTensor(scaled_anchors).index_select(1, LongTensor([0]))\n",
        "        anchor_h = FloatTensor(scaled_anchors).index_select(1, LongTensor([1]))\n",
        "        anchor_w = anchor_w.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(w.shape)\n",
        "        anchor_h = anchor_h.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(h.shape)\n",
        "        \n",
        "        # 计算调整后的先验框中心与宽高\n",
        "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
        "        pred_boxes[..., 0] = x.data + grid_x\n",
        "        pred_boxes[..., 1] = y.data + grid_y\n",
        "        pred_boxes[..., 2] = torch.exp(w.data) * anchor_w\n",
        "        pred_boxes[..., 3] = torch.exp(h.data) * anchor_h\n",
        "\n",
        "        # fig = plt.figure()\n",
        "        # ax = fig.add_subplot(121)\n",
        "        # if input_height==13:\n",
        "        #     plt.ylim(0,13)\n",
        "        #     plt.xlim(0,13)\n",
        "        # elif input_height==26:\n",
        "        #     plt.ylim(0,26)\n",
        "        #     plt.xlim(0,26)\n",
        "        # elif input_height==52:\n",
        "        #     plt.ylim(0,52)\n",
        "        #     plt.xlim(0,52)\n",
        "        # plt.scatter(grid_x.cpu(),grid_y.cpu())\n",
        "\n",
        "        # anchor_left = grid_x - anchor_w/2 \n",
        "        # anchor_top = grid_y - anchor_h/2 \n",
        "\n",
        "        # rect1 = plt.Rectangle([anchor_left[0,0,5,5],anchor_top[0,0,5,5]],anchor_w[0,0,5,5],anchor_h[0,0,5,5],color=\"r\",fill=False)\n",
        "        # rect2 = plt.Rectangle([anchor_left[0,1,5,5],anchor_top[0,1,5,5]],anchor_w[0,1,5,5],anchor_h[0,1,5,5],color=\"r\",fill=False)\n",
        "        # rect3 = plt.Rectangle([anchor_left[0,2,5,5],anchor_top[0,2,5,5]],anchor_w[0,2,5,5],anchor_h[0,2,5,5],color=\"r\",fill=False)\n",
        "\n",
        "        # ax.add_patch(rect1)\n",
        "        # ax.add_patch(rect2)\n",
        "        # ax.add_patch(rect3)\n",
        "\n",
        "        # ax = fig.add_subplot(122)\n",
        "        # if input_height==13:\n",
        "        #     plt.ylim(0,13)\n",
        "        #     plt.xlim(0,13)\n",
        "        # elif input_height==26:\n",
        "        #     plt.ylim(0,26)\n",
        "        #     plt.xlim(0,26)\n",
        "        # elif input_height==52:\n",
        "        #     plt.ylim(0,52)\n",
        "        #     plt.xlim(0,52)\n",
        "        # plt.scatter(grid_x.cpu(),grid_y.cpu())\n",
        "        # plt.scatter(pred_boxes[0,:,5,5,0].cpu(),pred_boxes[0,:,5,5,1].cpu(),c='r')\n",
        "\n",
        "        # pre_left = pred_boxes[...,0] - pred_boxes[...,2]/2 \n",
        "        # pre_top = pred_boxes[...,1] - pred_boxes[...,3]/2 \n",
        "\n",
        "        # rect1 = plt.Rectangle([pre_left[0,0,5,5],pre_top[0,0,5,5]],pred_boxes[0,0,5,5,2],pred_boxes[0,0,5,5,3],color=\"r\",fill=False)\n",
        "        # rect2 = plt.Rectangle([pre_left[0,1,5,5],pre_top[0,1,5,5]],pred_boxes[0,1,5,5,2],pred_boxes[0,1,5,5,3],color=\"r\",fill=False)\n",
        "        # rect3 = plt.Rectangle([pre_left[0,2,5,5],pre_top[0,2,5,5]],pred_boxes[0,2,5,5,2],pred_boxes[0,2,5,5,3],color=\"r\",fill=False)\n",
        "\n",
        "        # ax.add_patch(rect1)\n",
        "        # ax.add_patch(rect2)\n",
        "        # ax.add_patch(rect3)\n",
        "\n",
        "        # plt.show()\n",
        "        # 用于将输出调整为相对于416x416的大小\n",
        "        _scale = torch.Tensor([stride_w, stride_h] * 2).type(FloatTensor)\n",
        "        output = torch.cat((pred_boxes.view(batch_size, -1, 4) * _scale,\n",
        "                            conf.view(batch_size, -1, 1), pred_cls.view(batch_size, -1, self.num_classes)), -1)\n",
        "        return output.data\n",
        "        \n",
        "def letterbox_image(image, size):\n",
        "    iw, ih = image.size\n",
        "    w, h = size\n",
        "    scale = min(w/iw, h/ih)\n",
        "    nw = int(iw*scale)\n",
        "    nh = int(ih*scale)\n",
        "\n",
        "    image = image.resize((nw,nh), Image.BICUBIC)\n",
        "    new_image = Image.new('RGB', size, (128,128,128))\n",
        "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
        "    return new_image\n",
        "\n",
        "def yolo_correct_boxes(top, left, bottom, right, input_shape, image_shape):\n",
        "    new_shape = image_shape*np.min(input_shape/image_shape)\n",
        "\n",
        "    offset = (input_shape-new_shape)/2./input_shape\n",
        "    scale = input_shape/new_shape\n",
        "\n",
        "    box_yx = np.concatenate(((top+bottom)/2,(left+right)/2),axis=-1)/input_shape\n",
        "    box_hw = np.concatenate((bottom-top,right-left),axis=-1)/input_shape\n",
        "\n",
        "    box_yx = (box_yx - offset) * scale\n",
        "    box_hw *= scale\n",
        "\n",
        "    box_mins = box_yx - (box_hw / 2.)\n",
        "    box_maxes = box_yx + (box_hw / 2.)\n",
        "    boxes =  np.concatenate([\n",
        "        box_mins[:, 0:1],\n",
        "        box_mins[:, 1:2],\n",
        "        box_maxes[:, 0:1],\n",
        "        box_maxes[:, 1:2]\n",
        "    ],axis=-1)\n",
        "    boxes *= np.concatenate([image_shape, image_shape],axis=-1)\n",
        "    return boxes\n",
        "\n",
        "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
        "    \"\"\"\n",
        "        计算IOU\n",
        "    \"\"\"\n",
        "    if not x1y1x2y2:\n",
        "        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
        "        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
        "        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
        "        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
        "    else:\n",
        "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
        "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
        "\n",
        "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
        "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
        "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
        "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
        "\n",
        "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * \\\n",
        "                 torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n",
        "                 \n",
        "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
        "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
        "\n",
        "    iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "def non_max_suppression(prediction, num_classes, conf_thres=0.5, nms_thres=0.4):\n",
        "    # 求左上角和右下角\n",
        "    box_corner = prediction.new(prediction.shape)\n",
        "    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n",
        "    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n",
        "    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n",
        "    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n",
        "    prediction[:, :, :4] = box_corner[:, :, :4]\n",
        "\n",
        "    output = [None for _ in range(len(prediction))]\n",
        "    for image_i, image_pred in enumerate(prediction):\n",
        "        # 获得种类及其置信度\n",
        "        class_conf, class_pred = torch.max(image_pred[:, 5:5 + num_classes], 1, keepdim=True)\n",
        "\n",
        "        # 利用置信度进行第一轮筛选\n",
        "        conf_mask = (image_pred[:, 4]*class_conf[:, 0] >= conf_thres).squeeze()\n",
        "\n",
        "        image_pred = image_pred[conf_mask]\n",
        "        class_conf = class_conf[conf_mask]\n",
        "        class_pred = class_pred[conf_mask]\n",
        "        if not image_pred.size(0):\n",
        "            continue\n",
        "        # 获得的内容为(x1, y1, x2, y2, obj_conf, class_conf, class_pred)\n",
        "        detections = torch.cat((image_pred[:, :5], class_conf.float(), class_pred.float()), 1)\n",
        "\n",
        "        # 获得种类\n",
        "        unique_labels = detections[:, -1].cpu().unique()\n",
        "\n",
        "        if prediction.is_cuda:\n",
        "            unique_labels = unique_labels.cuda()\n",
        "            detections = detections.cuda()\n",
        "\n",
        "        for c in unique_labels:\n",
        "            # 获得某一类初步筛选后全部的预测结果\n",
        "            detections_class = detections[detections[:, -1] == c]\n",
        "\n",
        "            #------------------------------------------#\n",
        "            #   使用官方自带的非极大抑制会速度更快一些！\n",
        "            #------------------------------------------#\n",
        "            keep = nms(\n",
        "                detections_class[:, :4],\n",
        "                detections_class[:, 4]*detections_class[:, 5],\n",
        "                nms_thres\n",
        "            )\n",
        "            max_detections = detections_class[keep]\n",
        "            \n",
        "            # # 按照存在物体的置信度排序\n",
        "            # _, conf_sort_index = torch.sort(detections_class[:, 4]*detections_class[:, 5], descending=True)\n",
        "            # detections_class = detections_class[conf_sort_index]\n",
        "            # # 进行非极大抑制\n",
        "            # max_detections = []\n",
        "            # while detections_class.size(0):\n",
        "            #     # 取出这一类置信度最高的，一步一步往下判断，判断重合程度是否大于nms_thres，如果是则去除掉\n",
        "            #     max_detections.append(detections_class[0].unsqueeze(0))\n",
        "            #     if len(detections_class) == 1:\n",
        "            #         break\n",
        "            #     ious = bbox_iou(max_detections[-1], detections_class[1:])\n",
        "            #     detections_class = detections_class[1:][ious < nms_thres]\n",
        "            # # 堆叠\n",
        "            # max_detections = torch.cat(max_detections).data\n",
        "            \n",
        "            # Add max detections to outputs\n",
        "            output[image_i] = max_detections if output[image_i] is None else torch.cat(\n",
        "                (output[image_i], max_detections))\n",
        "\n",
        "    return output\n",
        "\n",
        "def merge_bboxes(bboxes, cutx, cuty):\n",
        "    merge_bbox = []\n",
        "    for i in range(len(bboxes)):\n",
        "        for box in bboxes[i]:\n",
        "            tmp_box = []\n",
        "            x1,y1,x2,y2 = box[0], box[1], box[2], box[3]\n",
        "\n",
        "            if i == 0:\n",
        "                if y1 > cuty or x1 > cutx:\n",
        "                    continue\n",
        "                if y2 >= cuty and y1 <= cuty:\n",
        "                    y2 = cuty\n",
        "                    if y2-y1 < 5:\n",
        "                        continue\n",
        "                if x2 >= cutx and x1 <= cutx:\n",
        "                    x2 = cutx\n",
        "                    if x2-x1 < 5:\n",
        "                        continue\n",
        "                \n",
        "            if i == 1:\n",
        "                if y2 < cuty or x1 > cutx:\n",
        "                    continue\n",
        "\n",
        "                if y2 >= cuty and y1 <= cuty:\n",
        "                    y1 = cuty\n",
        "                    if y2-y1 < 5:\n",
        "                        continue\n",
        "                \n",
        "                if x2 >= cutx and x1 <= cutx:\n",
        "                    x2 = cutx\n",
        "                    if x2-x1 < 5:\n",
        "                        continue\n",
        "\n",
        "            if i == 2:\n",
        "                if y2 < cuty or x2 < cutx:\n",
        "                    continue\n",
        "\n",
        "                if y2 >= cuty and y1 <= cuty:\n",
        "                    y1 = cuty\n",
        "                    if y2-y1 < 5:\n",
        "                        continue\n",
        "\n",
        "                if x2 >= cutx and x1 <= cutx:\n",
        "                    x1 = cutx\n",
        "                    if x2-x1 < 5:\n",
        "                        continue\n",
        "\n",
        "            if i == 3:\n",
        "                if y1 > cuty or x2 < cutx:\n",
        "                    continue\n",
        "\n",
        "                if y2 >= cuty and y1 <= cuty:\n",
        "                    y2 = cuty\n",
        "                    if y2-y1 < 5:\n",
        "                        continue\n",
        "\n",
        "                if x2 >= cutx and x1 <= cutx:\n",
        "                    x1 = cutx\n",
        "                    if x2-x1 < 5:\n",
        "                        continue\n",
        "\n",
        "            tmp_box.append(x1)\n",
        "            tmp_box.append(y1)\n",
        "            tmp_box.append(x2)\n",
        "            tmp_box.append(y2)\n",
        "            tmp_box.append(box[-1])\n",
        "            merge_bbox.append(tmp_box)\n",
        "    return merge_bbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OeUQpnmThZIE"
      },
      "source": [
        "import cv2  \n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
        "from PIL import Image\n",
        "\n",
        "def jaccard(_box_a, _box_b):\n",
        "    b1_x1, b1_x2 = _box_a[:, 0] - _box_a[:, 2] / 2, _box_a[:, 0] + _box_a[:, 2] / 2\n",
        "    b1_y1, b1_y2 = _box_a[:, 1] - _box_a[:, 3] / 2, _box_a[:, 1] + _box_a[:, 3] / 2\n",
        "    b2_x1, b2_x2 = _box_b[:, 0] - _box_b[:, 2] / 2, _box_b[:, 0] + _box_b[:, 2] / 2\n",
        "    b2_y1, b2_y2 = _box_b[:, 1] - _box_b[:, 3] / 2, _box_b[:, 1] + _box_b[:, 3] / 2\n",
        "    box_a = torch.zeros_like(_box_a)\n",
        "    box_b = torch.zeros_like(_box_b)\n",
        "    box_a[:, 0], box_a[:, 1], box_a[:, 2], box_a[:, 3] = b1_x1, b1_y1, b1_x2, b1_y2\n",
        "    box_b[:, 0], box_b[:, 1], box_b[:, 2], box_b[:, 3] = b2_x1, b2_y1, b2_x2, b2_y2\n",
        "    A = box_a.size(0)\n",
        "    B = box_b.size(0)\n",
        "    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),\n",
        "                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))\n",
        "    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),\n",
        "                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))\n",
        "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
        "\n",
        "    inter = inter[:, :, 0] * inter[:, :, 1]\n",
        "    # 计算先验框和真实框各自的面积\n",
        "    area_a = ((box_a[:, 2]-box_a[:, 0]) *\n",
        "              (box_a[:, 3]-box_a[:, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n",
        "    area_b = ((box_b[:, 2]-box_b[:, 0]) *\n",
        "              (box_b[:, 3]-box_b[:, 1])).unsqueeze(0).expand_as(inter)  # [A,B]\n",
        "    # 求IOU\n",
        "    union = area_a + area_b - inter\n",
        "    return inter / union  # [A,B]\n",
        "#---------------------------------------------------#\n",
        "#   平滑标签\n",
        "#---------------------------------------------------#\n",
        "def smooth_labels(y_true, label_smoothing,num_classes):\n",
        "    return y_true * (1.0 - label_smoothing) + label_smoothing / num_classes\n",
        "\n",
        "def box_ciou(b1, b2):\n",
        "    \"\"\"\n",
        "    输入为：\n",
        "    ----------\n",
        "    b1: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n",
        "    b2: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n",
        "    返回为：\n",
        "    -------\n",
        "    ciou: tensor, shape=(batch, feat_w, feat_h, anchor_num, 1)\n",
        "    \"\"\"\n",
        "    # 求出预测框左上角右下角\n",
        "    b1_xy = b1[..., :2]\n",
        "    b1_wh = b1[..., 2:4]\n",
        "    b1_wh_half = b1_wh/2.\n",
        "    b1_mins = b1_xy - b1_wh_half\n",
        "    b1_maxes = b1_xy + b1_wh_half\n",
        "    # 求出真实框左上角右下角\n",
        "    b2_xy = b2[..., :2]\n",
        "    b2_wh = b2[..., 2:4]\n",
        "    b2_wh_half = b2_wh/2.\n",
        "    b2_mins = b2_xy - b2_wh_half\n",
        "    b2_maxes = b2_xy + b2_wh_half\n",
        "\n",
        "    # 求真实框和预测框所有的iou\n",
        "    intersect_mins = torch.max(b1_mins, b2_mins)\n",
        "    intersect_maxes = torch.min(b1_maxes, b2_maxes)\n",
        "    intersect_wh = torch.max(intersect_maxes - intersect_mins, torch.zeros_like(intersect_maxes))\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
        "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
        "    union_area = b1_area + b2_area - intersect_area\n",
        "    iou = intersect_area / torch.clamp(union_area,min = 1e-6)\n",
        "\n",
        "    # 计算中心的差距\n",
        "    center_distance = torch.sum(torch.pow((b1_xy - b2_xy), 2), axis=-1)\n",
        "    \n",
        "    # 找到包裹两个框的最小框的左上角和右下角\n",
        "    enclose_mins = torch.min(b1_mins, b2_mins)\n",
        "    enclose_maxes = torch.max(b1_maxes, b2_maxes)\n",
        "    enclose_wh = torch.max(enclose_maxes - enclose_mins, torch.zeros_like(intersect_maxes))\n",
        "    # 计算对角线距离\n",
        "    enclose_diagonal = torch.sum(torch.pow(enclose_wh,2), axis=-1)\n",
        "    ciou = iou - 1.0 * (center_distance) / torch.clamp(enclose_diagonal,min = 1e-6)\n",
        "    \n",
        "    v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(b1_wh[..., 0]/torch.clamp(b1_wh[..., 1],min = 1e-6)) - torch.atan(b2_wh[..., 0]/torch.clamp(b2_wh[..., 1],min = 1e-6))), 2)\n",
        "    alpha = v / torch.clamp((1.0 - iou + v),min=1e-6)\n",
        "    ciou = ciou - alpha * v\n",
        "    return ciou\n",
        "  \n",
        "def clip_by_tensor(t,t_min,t_max):\n",
        "    t=t.float()\n",
        "    result = (t >= t_min).float() * t + (t < t_min).float() * t_min\n",
        "    result = (result <= t_max).float() * result + (result > t_max).float() * t_max\n",
        "    return result\n",
        "\n",
        "def MSELoss(pred,target):\n",
        "    return (pred-target)**2\n",
        "\n",
        "def BCELoss(pred,target):\n",
        "    epsilon = 1e-7\n",
        "    pred = clip_by_tensor(pred, epsilon, 1.0 - epsilon)\n",
        "    output = -target * torch.log(pred) - (1.0 - target) * torch.log(1.0 - pred)\n",
        "    return output\n",
        "\n",
        "class YOLOLoss(nn.Module):\n",
        "    def __init__(self, anchors, num_classes, img_size, label_smooth=0, cuda=True):\n",
        "        super(YOLOLoss, self).__init__()\n",
        "        self.anchors = anchors\n",
        "        self.num_anchors = len(anchors)\n",
        "        self.num_classes = num_classes\n",
        "        self.bbox_attrs = 5 + num_classes\n",
        "        self.img_size = img_size\n",
        "        self.feature_length = [img_size[0]//32,img_size[0]//16,img_size[0]//8]\n",
        "        self.label_smooth = label_smooth\n",
        "\n",
        "        self.ignore_threshold = 0.5\n",
        "        self.lambda_conf = 1.0\n",
        "        self.lambda_cls = 1.0\n",
        "        self.lambda_loc = 1.0\n",
        "        self.cuda = cuda\n",
        "\n",
        "    def forward(self, input, targets=None):\n",
        "        # input为bs,3*(5+num_classes),13,13\n",
        "        \n",
        "        # 一共多少张图片\n",
        "        bs = input.size(0)\n",
        "        # 特征层的高\n",
        "        in_h = input.size(2)\n",
        "        # 特征层的宽\n",
        "        in_w = input.size(3)\n",
        "\n",
        "        # 计算步长\n",
        "        # 每一个特征点对应原来的图片上多少个像素点\n",
        "        # 如果特征层为13x13的话，一个特征点就对应原来的图片上的32个像素点\n",
        "        stride_h = self.img_size[1] / in_h\n",
        "        stride_w = self.img_size[0] / in_w\n",
        "\n",
        "        # 把先验框的尺寸调整成特征层大小的形式\n",
        "        # 计算出先验框在特征层上对应的宽高\n",
        "        scaled_anchors = [(a_w / stride_w, a_h / stride_h) for a_w, a_h in self.anchors]\n",
        "        # bs,3*(5+num_classes),13,13 -> bs,3,13,13,(5+num_classes)\n",
        "        prediction = input.view(bs, int(self.num_anchors/3),\n",
        "                                self.bbox_attrs, in_h, in_w).permute(0, 1, 3, 4, 2).contiguous()\n",
        "        \n",
        "        # 对prediction预测进行调整\n",
        "        conf = torch.sigmoid(prediction[..., 4])  # Conf\n",
        "        pred_cls = torch.sigmoid(prediction[..., 5:])  # Cls pred.\n",
        "\n",
        "        # 找到哪些先验框内部包含物体\n",
        "        mask, noobj_mask, t_box, tconf, tcls, box_loss_scale_x, box_loss_scale_y = self.get_target(targets, scaled_anchors,in_w, in_h,self.ignore_threshold)\n",
        "\n",
        "        noobj_mask, pred_boxes_for_ciou = self.get_ignore(prediction, targets, scaled_anchors, in_w, in_h, noobj_mask)\n",
        "\n",
        "        if self.cuda:\n",
        "            mask, noobj_mask = mask.cuda(), noobj_mask.cuda()\n",
        "            box_loss_scale_x, box_loss_scale_y= box_loss_scale_x.cuda(), box_loss_scale_y.cuda()\n",
        "            tconf, tcls = tconf.cuda(), tcls.cuda()\n",
        "            pred_boxes_for_ciou = pred_boxes_for_ciou.cuda()\n",
        "            t_box = t_box.cuda()\n",
        "\n",
        "        box_loss_scale = 2-box_loss_scale_x*box_loss_scale_y\n",
        "        #  losses.\n",
        "        ciou = (1 - box_ciou( pred_boxes_for_ciou[mask.bool()], t_box[mask.bool()]))* box_loss_scale[mask.bool()]\n",
        "\n",
        "        loss_loc = torch.sum(ciou / bs)\n",
        "        loss_conf = torch.sum(BCELoss(conf, mask) * mask / bs) + \\\n",
        "                    torch.sum(BCELoss(conf, mask) * noobj_mask / bs)\n",
        "                    \n",
        "        # print(smooth_labels(tcls[mask == 1],self.label_smooth,self.num_classes))\n",
        "        loss_cls = torch.sum(BCELoss(pred_cls[mask == 1], smooth_labels(tcls[mask == 1],self.label_smooth,self.num_classes))/bs)\n",
        "        # print(loss_loc,loss_conf,loss_cls)\n",
        "        loss = loss_conf * self.lambda_conf + loss_cls * self.lambda_cls + loss_loc * self.lambda_loc\n",
        "        return loss, loss_conf.item(), loss_cls.item(), loss_loc.item()\n",
        "\n",
        "    def get_target(self, target, anchors, in_w, in_h, ignore_threshold):\n",
        "        # 计算一共有多少张图片\n",
        "        bs = len(target)\n",
        "        # 获得先验框\n",
        "        anchor_index = [[0,1,2],[3,4,5],[6,7,8]][self.feature_length.index(in_w)]\n",
        "        subtract_index = [0,3,6][self.feature_length.index(in_w)]\n",
        "        # 创建全是0或者全是1的阵列\n",
        "        mask = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        noobj_mask = torch.ones(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "\n",
        "        tx = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        ty = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        tw = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        th = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        t_box = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, 4, requires_grad=False)\n",
        "        tconf = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        tcls = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, self.num_classes, requires_grad=False)\n",
        "\n",
        "        box_loss_scale_x = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        box_loss_scale_y = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        for b in range(bs):\n",
        "            if len(target[b])==0:\n",
        "                continue\n",
        "            # 计算出在特征层上的点位\n",
        "            gxs = target[b][:, 0:1] * in_w\n",
        "            gys = target[b][:, 1:2] * in_h\n",
        "            \n",
        "            gws = target[b][:, 2:3] * in_w\n",
        "            ghs = target[b][:, 3:4] * in_h\n",
        "\n",
        "            # 计算出属于哪个网格\n",
        "            gis = torch.floor(gxs)\n",
        "            gjs = torch.floor(gys)\n",
        "            \n",
        "            # 计算真实框的位置\n",
        "            gt_box = torch.FloatTensor(torch.cat([torch.zeros_like(gws), torch.zeros_like(ghs), gws, ghs], 1))\n",
        "            \n",
        "            # 计算出所有先验框的位置\n",
        "            anchor_shapes = torch.FloatTensor(torch.cat((torch.zeros((self.num_anchors, 2)), torch.FloatTensor(anchors)), 1))\n",
        "            # 计算重合程度\n",
        "            anch_ious = jaccard(gt_box, anchor_shapes)\n",
        "\n",
        "            # Find the best matching anchor box\n",
        "            best_ns = torch.argmax(anch_ious,dim=-1)\n",
        "            for i, best_n in enumerate(best_ns):\n",
        "                if best_n not in anchor_index:\n",
        "                    continue\n",
        "                # Masks\n",
        "                gi = gis[i].long()\n",
        "                gj = gjs[i].long()\n",
        "                gx = gxs[i]\n",
        "                gy = gys[i]\n",
        "                gw = gws[i]\n",
        "                gh = ghs[i]\n",
        "                if (gj < in_h) and (gi < in_w):\n",
        "                    best_n = best_n - subtract_index\n",
        "                    # 判定哪些先验框内部真实的存在物体\n",
        "                    noobj_mask[b, best_n, gj, gi] = 0\n",
        "                    mask[b, best_n, gj, gi] = 1\n",
        "                    # 计算先验框中心调整参数\n",
        "                    tx[b, best_n, gj, gi] = gx\n",
        "                    ty[b, best_n, gj, gi] = gy\n",
        "                    # 计算先验框宽高调整参数\n",
        "                    tw[b, best_n, gj, gi] = gw\n",
        "                    th[b, best_n, gj, gi] = gh\n",
        "                    # 用于获得xywh的比例\n",
        "                    box_loss_scale_x[b, best_n, gj, gi] = target[b][i, 2]\n",
        "                    box_loss_scale_y[b, best_n, gj, gi] = target[b][i, 3]\n",
        "                    # 物体置信度\n",
        "                    tconf[b, best_n, gj, gi] = 1\n",
        "                    # 种类\n",
        "                    tcls[b, best_n, gj, gi, target[b][i, 4].long()] = 1\n",
        "                else:\n",
        "                    print('Step {0} out of bound'.format(b))\n",
        "                    print('gj: {0}, height: {1} | gi: {2}, width: {3}'.format(gj, in_h, gi, in_w))\n",
        "                    continue\n",
        "        t_box[...,0] = tx\n",
        "        t_box[...,1] = ty\n",
        "        t_box[...,2] = tw\n",
        "        t_box[...,3] = th\n",
        "        return mask, noobj_mask, t_box, tconf, tcls, box_loss_scale_x, box_loss_scale_y\n",
        "\n",
        "\n",
        "    def get_ignore(self,prediction,target,scaled_anchors,in_w, in_h,noobj_mask):\n",
        "        bs = len(target)\n",
        "        anchor_index = [[0,1,2],[3,4,5],[6,7,8]][self.feature_length.index(in_w)]\n",
        "        scaled_anchors = np.array(scaled_anchors)[anchor_index]\n",
        "        # 先验框的中心位置的调整参数\n",
        "        x = torch.sigmoid(prediction[..., 0])  \n",
        "        y = torch.sigmoid(prediction[..., 1])\n",
        "        # 先验框的宽高调整参数\n",
        "        w = prediction[..., 2]  # Width\n",
        "        h = prediction[..., 3]  # Height\n",
        "\n",
        "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
        "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
        "\n",
        "        # 生成网格，先验框中心，网格左上角\n",
        "        grid_x = torch.linspace(0, in_w - 1, in_w).repeat(in_w, 1).repeat(\n",
        "            int(bs*self.num_anchors/3), 1, 1).view(x.shape).type(FloatTensor)\n",
        "        grid_y = torch.linspace(0, in_h - 1, in_h).repeat(in_h, 1).t().repeat(\n",
        "            int(bs*self.num_anchors/3), 1, 1).view(y.shape).type(FloatTensor)\n",
        "\n",
        "        # 生成先验框的宽高\n",
        "        anchor_w = FloatTensor(scaled_anchors).index_select(1, LongTensor([0]))\n",
        "        anchor_h = FloatTensor(scaled_anchors).index_select(1, LongTensor([1]))\n",
        "        \n",
        "        anchor_w = anchor_w.repeat(bs, 1).repeat(1, 1, in_h * in_w).view(w.shape)\n",
        "        anchor_h = anchor_h.repeat(bs, 1).repeat(1, 1, in_h * in_w).view(h.shape)\n",
        "        \n",
        "        # 计算调整后的先验框中心与宽高\n",
        "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
        "        pred_boxes[..., 0] = x + grid_x\n",
        "        pred_boxes[..., 1] = y + grid_y\n",
        "        pred_boxes[..., 2] = torch.exp(w) * anchor_w\n",
        "        pred_boxes[..., 3] = torch.exp(h) * anchor_h\n",
        "        for i in range(bs):\n",
        "            pred_boxes_for_ignore = pred_boxes[i]\n",
        "            pred_boxes_for_ignore = pred_boxes_for_ignore.view(-1, 4)\n",
        "            if len(target[i]) > 0:\n",
        "                gx = target[i][:, 0:1] * in_w\n",
        "                gy = target[i][:, 1:2] * in_h\n",
        "                gw = target[i][:, 2:3] * in_w\n",
        "                gh = target[i][:, 3:4] * in_h\n",
        "                gt_box = torch.FloatTensor(torch.cat([gx, gy, gw, gh],-1)).type(FloatTensor)\n",
        "\n",
        "                anch_ious = jaccard(gt_box, pred_boxes_for_ignore)\n",
        "                anch_ious_max, _ = torch.max(anch_ious,dim=0)\n",
        "                anch_ious_max = anch_ious_max.view(pred_boxes[i].size()[:3])\n",
        "                noobj_mask[i][anch_ious_max>self.ignore_threshold] = 0\n",
        "        return noobj_mask, pred_boxes\n",
        "\n",
        "\n",
        "def rand(a=0, b=1):\n",
        "    return np.random.rand()*(b-a) + a\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "94ZXZw8wq1r4"
      },
      "source": [
        "class Generator(object):\n",
        "    def __init__(self,batch_size, box_info, train_lines, path, image_size,\n",
        "                 ):\n",
        "        self.box_info = box_info\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.train_lines = train_lines\n",
        "        self.train_batches = len(train_lines)\n",
        "        self.image_size = image_size\n",
        "        \n",
        "    def get_random_data(self, annotation_line, input_shape, jitter=.3, hue=.1, sat=1.5, val=1.5):\n",
        "        '''r实时数据增强的随机预处理'''\n",
        "        line = annotation_line\n",
        "        image = Image.open(line[0])\n",
        "        iw, ih = image.size\n",
        "        h, w = input_shape\n",
        "        box = np.array([np.array(list(map(float, box.split(',')))) for box in line[1:]])\n",
        "        box[:,0] = box[:,0]*iw\n",
        "        box[:,1] = box[:,1]*ih\n",
        "        box[:,2] = box[:,2]*iw\n",
        "        box[:,3] = box[:,3]*ih\n",
        "        box = box.astype(int)\n",
        "        # P = []\n",
        "        # for Z in line[1:]:\n",
        "        #   P.append(Z)\n",
        "        # box = np.array(P)\n",
        "\n",
        "        # resize image\n",
        "        new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
        "        scale = rand(.5, 1.5)\n",
        "        if new_ar < 1:\n",
        "            nh = int(scale*h)\n",
        "            nw = int(nh*new_ar)\n",
        "        else:\n",
        "            nw = int(scale*w)\n",
        "            nh = int(nw/new_ar)\n",
        "        image = image.resize((nw,nh), Image.BICUBIC)\n",
        "\n",
        "        # place image\n",
        "        dx = int(rand(0, w-nw))\n",
        "        dy = int(rand(0, h-nh))\n",
        "        new_image = Image.new('RGB', (w,h), (128,128,128))\n",
        "        new_image.paste(image, (dx, dy))\n",
        "        image = new_image\n",
        "\n",
        "        # flip image or not\n",
        "        flip = rand()<.5\n",
        "        if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "        # distort image\n",
        "        hue = rand(-hue, hue)\n",
        "        sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
        "        val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
        "        x = cv2.cvtColor(np.array(image,np.float32)/255, cv2.COLOR_RGB2HSV)\n",
        "        x[..., 0] += hue*360\n",
        "        x[..., 0][x[..., 0]>1] -= 1\n",
        "        x[..., 0][x[..., 0]<0] += 1\n",
        "        x[..., 1] *= sat\n",
        "        x[..., 2] *= val\n",
        "        x[x[:,:, 0]>360, 0] = 360\n",
        "        x[:, :, 1:][x[:, :, 1:]>1] = 1\n",
        "        x[x<0] = 0\n",
        "        image_data = cv2.cvtColor(x, cv2.COLOR_HSV2RGB)*255\n",
        "\n",
        "        # correct boxes\n",
        "        box_data = np.zeros((len(box),5))\n",
        "        if len(box)>0:\n",
        "            np.random.shuffle(box)\n",
        "            box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
        "            box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
        "            if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
        "            box[:, 0:2][box[:, 0:2]<0] = 0\n",
        "            box[:, 2][box[:, 2]>w] = w\n",
        "            box[:, 3][box[:, 3]>h] = h\n",
        "            box_w = box[:, 2] - box[:, 0]\n",
        "            box_h = box[:, 3] - box[:, 1]\n",
        "            box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
        "            box_data = np.zeros((len(box),5))\n",
        "            box_data[:len(box)] = box\n",
        "        if len(box) == 0:\n",
        "            return image_data, []\n",
        "\n",
        "        if (box_data[:,:4]>0).any():\n",
        "            return image_data, box_data\n",
        "        else:\n",
        "            return image_data, []\n",
        "\n",
        "    def get_random_data_with_Mosaic(self, annotation_line, input_shape, hue=.1, sat=1.5, val=1.5):\n",
        "        '''random preprocessing for real-time data augmentation'''\n",
        "        h, w = input_shape\n",
        "        min_offset_x = 0.4\n",
        "        min_offset_y = 0.4\n",
        "        scale_low = 1-min(min_offset_x,min_offset_y)\n",
        "        scale_high = scale_low+0.2\n",
        "\n",
        "        image_datas = [] \n",
        "        box_datas = []\n",
        "        index = 0\n",
        "\n",
        "        place_x = [0,0,int(w*min_offset_x),int(w*min_offset_x)]\n",
        "        place_y = [0,int(h*min_offset_y),int(h*min_offset_y),0]\n",
        "        for line in annotation_line:\n",
        "            # 每一行进行分割\n",
        "            line_content = line\n",
        "            # 打开图片\n",
        "            image = Image.open(line_content[0])\n",
        "            image = image.convert(\"RGB\") \n",
        "            # 图片的大小\n",
        "            iw, ih = image.size\n",
        "            # 保存框的位置\n",
        "            box = np.array([np.array(list(map(float, box.split(',')))) for box in line_content[1:]])\n",
        "            box[:,0] = box[:,0]*iw\n",
        "            box[:,1] = box[:,1]*ih\n",
        "            box[:,2] = box[:,2]*iw\n",
        "            box[:,3] = box[:,3]*ih\n",
        "            box = box.astype(int)\n",
        "            # P = []\n",
        "            # for Z in line_content[1:]:\n",
        "            #   P.append(Z)\n",
        "            # box = np.array(P)\n",
        "            \n",
        "            # 是否翻转图片\n",
        "            flip = rand()<.5\n",
        "            if flip and len(box)>0:\n",
        "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                box[:, [0,2]] = iw - box[:, [2,0]]\n",
        "\n",
        "            # 对输入进来的图片进行缩放\n",
        "            new_ar = w/h\n",
        "            scale = rand(scale_low, scale_high)\n",
        "            if new_ar < 1:\n",
        "                nh = int(scale*h)\n",
        "                nw = int(nh*new_ar)\n",
        "            else:\n",
        "                nw = int(scale*w)\n",
        "                nh = int(nw/new_ar)\n",
        "            image = image.resize((nw,nh), Image.BICUBIC)\n",
        "\n",
        "            # 进行色域变换\n",
        "            hue = rand(-hue, hue)\n",
        "            sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
        "            val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
        "            x = cv2.cvtColor(np.array(image,np.float32)/255, cv2.COLOR_RGB2HSV)\n",
        "            x[..., 0] += hue*360\n",
        "            x[..., 0][x[..., 0]>1] -= 1\n",
        "            x[..., 0][x[..., 0]<0] += 1\n",
        "            x[..., 1] *= sat\n",
        "            x[..., 2] *= val\n",
        "            x[x[:,:, 0]>360, 0] = 360\n",
        "            x[:, :, 1:][x[:, :, 1:]>1] = 1\n",
        "            x[x<0] = 0\n",
        "            image = cv2.cvtColor(x, cv2.COLOR_HSV2RGB) # numpy array, 0 to 1\n",
        "            \n",
        "            image = Image.fromarray((image*255).astype(np.uint8))\n",
        "            # 将图片进行放置，分别对应四张分割图片的位置\n",
        "            dx = place_x[index]\n",
        "            dy = place_y[index]\n",
        "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
        "            new_image.paste(image, (dx, dy))\n",
        "            image_data = np.array(new_image)\n",
        "\n",
        "            \n",
        "            index = index + 1\n",
        "            box_data = []\n",
        "            # 对box进行重新处理\n",
        "            if len(box)>0:\n",
        "                np.random.shuffle(box)\n",
        "                box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
        "                box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
        "                box[:, 0:2][box[:, 0:2]<0] = 0\n",
        "                box[:, 2][box[:, 2]>w] = w\n",
        "                box[:, 3][box[:, 3]>h] = h\n",
        "                box_w = box[:, 2] - box[:, 0]\n",
        "                box_h = box[:, 3] - box[:, 1]\n",
        "                box = box[np.logical_and(box_w>1, box_h>1)]\n",
        "                box_data = np.zeros((len(box),5))\n",
        "                box_data[:len(box)] = box\n",
        "            \n",
        "            image_datas.append(image_data)\n",
        "            box_datas.append(box_data)\n",
        "\n",
        "        # 将图片分割，放在一起\n",
        "        cutx = np.random.randint(int(w*min_offset_x), int(w*(1 - min_offset_x)))\n",
        "        cuty = np.random.randint(int(h*min_offset_y), int(h*(1 - min_offset_y)))\n",
        "\n",
        "        new_image = np.zeros([h,w,3])\n",
        "        new_image[:cuty, :cutx, :] = image_datas[0][:cuty, :cutx, :]\n",
        "        new_image[cuty:, :cutx, :] = image_datas[1][cuty:, :cutx, :]\n",
        "        new_image[cuty:, cutx:, :] = image_datas[2][cuty:, cutx:, :]\n",
        "        new_image[:cuty, cutx:, :] = image_datas[3][:cuty, cutx:, :]\n",
        "\n",
        "        # 对框进行进一步的处理\n",
        "        new_boxes = np.array(merge_bboxes(box_datas, cutx, cuty))\n",
        "\n",
        "        if len(new_boxes) == 0:\n",
        "            return new_image, []\n",
        "        if (new_boxes[:,:4]>0).any():\n",
        "            return new_image, new_boxes\n",
        "        else:\n",
        "            return new_image, []\n",
        "\n",
        "    def generate(self, train = True, mosaic = True):\n",
        "        while True:\n",
        "            # lines = self.train_lines\n",
        "            # box_info = self.box_info\n",
        "            # line = []\n",
        "            # n = self.train_batches\n",
        "            # for j in range(0, len(lines)):\n",
        "            #   sub_lines = []\n",
        "            #   sub_box_info = box_info.loc[box_info[\"img_id\"] == lines[j],]\n",
        "            #   sub_lines.append(self.path + lines[j])\n",
        "            #   for i in range(0, len(sub_box_info)):\n",
        "            #     X = str([sub_box_info.iloc[i,1], sub_box_info.iloc[i,4], sub_box_info.iloc[i,2], sub_box_info.iloc[i,3], sub_box_info.iloc[i,0]]).strip('[]')\n",
        "            #     sub_lines.append(X)\n",
        "            #   lines.append(sub_lines)\n",
        "            # index = index % n\n",
        "\n",
        "            shuffle(self.train_lines)\n",
        "            lines = self.train_lines\n",
        "            box_info = self.box_info\n",
        "            inputs = []\n",
        "            targets = []\n",
        "            line = []\n",
        "            flag = True\n",
        "            n = len(lines)\n",
        "            for j in range(0, len(lines)):\n",
        "              sub_lines = []\n",
        "              sub_box_info = box_info.loc[box_info[\"img_id\"] == lines[j],]\n",
        "              sub_lines.append(self.path + lines[j])\n",
        "              for i in range(0, len(sub_box_info)):\n",
        "                X = str([sub_box_info.iloc[i,1], sub_box_info.iloc[i,4], sub_box_info.iloc[i,2], sub_box_info.iloc[i,3], sub_box_info.iloc[i,0]]).strip('[]')\n",
        "                sub_lines.append(X)\n",
        "              line.append(sub_lines)\n",
        "\n",
        "\n",
        "            for i in range(len(line)):\n",
        "                if mosaic == True:\n",
        "                    if flag and (i+4) < n:\n",
        "                        img,y = self.get_random_data_with_Mosaic(line[i:i+4], self.image_size[0:2])\n",
        "                        i = (i+4) % n\n",
        "                    else:\n",
        "                        img,y = self.get_random_data(line[i], self.image_size[0:2])\n",
        "                        i = (i+1) % n\n",
        "                    flag = bool(1-flag)\n",
        "                else:\n",
        "                    img,y = self.get_random_data(line[i], self.image_size[0:2])\n",
        "                    i = (i+1) % n\n",
        "                if len(y)!=0:\n",
        "                    boxes = np.array(y[:,:4],dtype=np.float32)\n",
        "                    boxes[:,0] = boxes[:,0]/self.image_size[1]\n",
        "                    boxes[:,1] = boxes[:,1]/self.image_size[0]\n",
        "                    boxes[:,2] = boxes[:,2]/self.image_size[1]\n",
        "                    boxes[:,3] = boxes[:,3]/self.image_size[0]\n",
        "\n",
        "                    boxes = np.maximum(np.minimum(boxes,1),0)\n",
        "                    boxes[:,2] = boxes[:,2] - boxes[:,0]\n",
        "                    boxes[:,3] = boxes[:,3] - boxes[:,1]\n",
        "    \n",
        "                    boxes[:,0] = boxes[:,0] + boxes[:,2]/2\n",
        "                    boxes[:,1] = boxes[:,1] + boxes[:,3]/2\n",
        "                    y = np.concatenate([boxes,y[:,-1:]],axis=-1)\n",
        "                    \n",
        "                img = np.array(img,dtype = np.float32)\n",
        "\n",
        "                inputs.append(np.transpose(img/255.0,(2,0,1)))              \n",
        "                targets.append(np.array(y,dtype = np.float32))\n",
        "                if len(targets) == self.batch_size:\n",
        "                    tmp_inp = np.array(inputs)\n",
        "                    tmp_targets = targets\n",
        "                    inputs = []\n",
        "                    targets = []\n",
        "                    yield tmp_inp, tmp_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2it6FiBAhb9Q"
      },
      "source": [
        "# 建立loss函数\n",
        "yolo_losses = []\n",
        "for i in range(3):\n",
        "    yolo_losses.append(YOLOLoss(np.reshape(anchors,[-1,2]),num_classes, \\\n",
        "                            (input_shape[1], input_shape[0]), smoooth_label, Cuda))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "INXoEKVYhfPd"
      },
      "source": [
        "# 0.1用于验证，0.9用于训练\n",
        "val_split = 0.1\n",
        "img_ids = box_info[\"img_id\"].unique()\n",
        "np.random.seed(10101)\n",
        "np.random.shuffle(img_ids)\n",
        "np.random.seed(None)\n",
        "num_val = int(len(img_ids)*val_split)\n",
        "num_train = len(img_ids) - num_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x1Gk2Iz1imTt"
      },
      "source": [
        "from random import shuffle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
        "import cv2\n",
        "\n",
        "# train_lines = img_ids[:num_train]\n",
        "# for j in range(0, len(train_lines)):\n",
        "#   sub_lines = []\n",
        "#   sub_box_info = box_info.loc[box_info[\"img_id\"] == train_lines[j],]\n",
        "#   sub_lines.append(train_lines[j])\n",
        "#   for i in range(0, len(sub_box_info)):\n",
        "#     X = str([sub_box_info.iloc[i,1], sub_box_info.iloc[i,4], sub_box_info.iloc[i,2], sub_box_info.iloc[i,3], sub_box_info.iloc[i,0]]).strip('[]')\n",
        "#     sub_lines.append(X)\n",
        "#   lines.append(sub_lines)\n",
        "# train_batches = len(lines)\n",
        "# n = train_batches\n",
        "# index = train_batches\n",
        "# index = index % n\n",
        "# annotation_line = lines[index:index + 4]\n",
        "\n",
        "class YoloDataset(Dataset):\n",
        "    def __init__(self, box_info, train_lines, path, image_size, mosaic=True):\n",
        "        super(YoloDataset, self).__init__()\n",
        "\n",
        "        self.train_lines = train_lines\n",
        "        self.box_info = box_info\n",
        "        self.train_batches = len(train_lines)\n",
        "        self.image_size = image_size\n",
        "        self.mosaic = mosaic\n",
        "        self.flag = True\n",
        "        self.path = path\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.train_batches\n",
        "\n",
        "    def rand(self, a=0, b=1):\n",
        "        return np.random.rand() * (b - a) + a\n",
        "\n",
        "    def get_random_data(self, annotation_line, input_shape, jitter=.3, hue=.1, sat=1.5, val=1.5):\n",
        "        \"\"\"实时数据增强的随机预处理\"\"\"\n",
        "        line = annotation_line\n",
        "        image = Image.open(line[0])\n",
        "        iw, ih = image.size\n",
        "        h, w = input_shape\n",
        "        box = np.array([np.array(list(map(float, box.split(',')))) for box in line[1:]])\n",
        "        box[:,0] = box[:,0]*iw\n",
        "        box[:,1] = box[:,1]*ih\n",
        "        box[:,2] = box[:,2]*iw\n",
        "        box[:,3] = box[:,3]*ih\n",
        "        box = box.astype(int)\n",
        "        # P = []\n",
        "        # for Z in line[1:]:\n",
        "        #   P.append(Z)\n",
        "        # box = np.array(P)\n",
        "\n",
        "        # 调整图片大小\n",
        "        new_ar = w / h * self.rand(1 - jitter, 1 + jitter) / self.rand(1 - jitter, 1 + jitter)\n",
        "        scale = self.rand(.5, 1.5)\n",
        "        if new_ar < 1:\n",
        "            nh = int(scale * h)\n",
        "            nw = int(nh * new_ar)\n",
        "        else:\n",
        "            nw = int(scale * w)\n",
        "            nh = int(nw / new_ar)\n",
        "        image = image.resize((nw, nh), Image.BICUBIC)\n",
        "\n",
        "        # 放置图片\n",
        "        dx = int(self.rand(0, w - nw))\n",
        "        dy = int(self.rand(0, h - nh))\n",
        "        new_image = Image.new('RGB', (w, h),\n",
        "                              (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)))\n",
        "        new_image.paste(image, (dx, dy))\n",
        "        image = new_image\n",
        "\n",
        "        # 是否翻转图片\n",
        "        flip = self.rand() < .5\n",
        "        if flip:\n",
        "            image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "        # 色域变换\n",
        "        hue = self.rand(-hue, hue)\n",
        "        sat = self.rand(1, sat) if self.rand() < .5 else 1 / self.rand(1, sat)\n",
        "        val = self.rand(1, val) if self.rand() < .5 else 1 / self.rand(1, val)\n",
        "        x = cv2.cvtColor(np.array(image,np.float32)/255, cv2.COLOR_RGB2HSV)\n",
        "        x[..., 0] += hue*360\n",
        "        x[..., 0][x[..., 0]>1] -= 1\n",
        "        x[..., 0][x[..., 0]<0] += 1\n",
        "        x[..., 1] *= sat\n",
        "        x[..., 2] *= val\n",
        "        x[x[:,:, 0]>360, 0] = 360\n",
        "        x[:, :, 1:][x[:, :, 1:]>1] = 1\n",
        "        x[x<0] = 0\n",
        "        image_data = cv2.cvtColor(x, cv2.COLOR_HSV2RGB)*255\n",
        "\n",
        "        # 调整目标框坐标\n",
        "        box_data = np.zeros((len(box), 5))\n",
        "        if len(box) > 0:\n",
        "            np.random.shuffle(box)\n",
        "            box[:, [0, 2]] = box[:, [0, 2]] * nw / iw + dx\n",
        "            box[:, [1, 3]] = box[:, [1, 3]] * nh / ih + dy\n",
        "            if flip:\n",
        "                box[:, [0, 2]] = w - box[:, [2, 0]]\n",
        "            box[:, 0:2][box[:, 0:2] < 0] = 0\n",
        "            box[:, 2][box[:, 2] > w] = w\n",
        "            box[:, 3][box[:, 3] > h] = h\n",
        "            box_w = box[:, 2] - box[:, 0]\n",
        "            box_h = box[:, 3] - box[:, 1]\n",
        "            box = box[np.logical_and(box_w > 1, box_h > 1)]  # 保留有效框\n",
        "            box_data = np.zeros((len(box), 5))\n",
        "            box_data[:len(box)] = box\n",
        "        if len(box) == 0:\n",
        "            return image_data, []\n",
        "\n",
        "        if (box_data[:, :4] > 0).any():\n",
        "            return image_data, box_data\n",
        "        else:\n",
        "            return image_data, []\n",
        "\n",
        "    def get_random_data_with_Mosaic(self, annotation_line, input_shape, hue=.1, sat=1.5, val=1.5):\n",
        "        h, w = input_shape\n",
        "        min_offset_x = 0.3\n",
        "        min_offset_y = 0.3\n",
        "        scale_low = 1 - min(min_offset_x, min_offset_y)\n",
        "        scale_high = scale_low + 0.2\n",
        "\n",
        "        image_datas = []\n",
        "        box_datas = []\n",
        "        index = 0\n",
        "\n",
        "        place_x = [0, 0, int(w * min_offset_x), int(w * min_offset_x)]\n",
        "        place_y = [0, int(h * min_offset_y), int(h * min_offset_y), 0]\n",
        "        for line in annotation_line:\n",
        "            # 每一行进行分割\n",
        "            line_content = line\n",
        "            # 打开图片\n",
        "            image = Image.open(line_content[0])\n",
        "            image = image.convert(\"RGB\")\n",
        "            # 图片的大小\n",
        "            iw, ih = image.size\n",
        "            # 保存框的位置\n",
        "            box = np.array([np.array(list(map(float, box.split(',')))) for box in line_content[1:]])\n",
        "            box[:,0] = box[:,0]*iw\n",
        "            box[:,1] = box[:,1]*ih\n",
        "            box[:,2] = box[:,2]*iw\n",
        "            box[:,3] = box[:,3]*ih\n",
        "            box = box.astype(int)\n",
        "            # P = []\n",
        "            # for Z in line_content[1:]:\n",
        "            #   P.append(Z)\n",
        "            # box = np.array(P)\n",
        "\n",
        "            # 是否翻转图片\n",
        "            flip = self.rand() < .5\n",
        "            if flip and len(box) > 0:\n",
        "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                box[:, [0, 2]] = iw - box[:, [2, 0]]\n",
        "\n",
        "            # 对输入进来的图片进行缩放\n",
        "            new_ar = w / h\n",
        "            scale = self.rand(scale_low, scale_high)\n",
        "            if new_ar < 1:\n",
        "                nh = int(scale * h)\n",
        "                nw = int(nh * new_ar)\n",
        "            else:\n",
        "                nw = int(scale * w)\n",
        "                nh = int(nw / new_ar)\n",
        "            image = image.resize((nw, nh), Image.BICUBIC)\n",
        "\n",
        "            # 进行色域变换\n",
        "            hue = self.rand(-hue, hue)\n",
        "            sat = self.rand(1, sat) if self.rand() < .5 else 1 / self.rand(1, sat)\n",
        "            val = self.rand(1, val) if self.rand() < .5 else 1 / self.rand(1, val)\n",
        "            x = cv2.cvtColor(np.array(image,np.float32)/255, cv2.COLOR_RGB2HSV)\n",
        "            x[..., 0] += hue*360\n",
        "            x[..., 0][x[..., 0]>1] -= 1\n",
        "            x[..., 0][x[..., 0]<0] += 1\n",
        "            x[..., 1] *= sat\n",
        "            x[..., 2] *= val\n",
        "            x[x[:,:, 0]>360, 0] = 360\n",
        "            x[:, :, 1:][x[:, :, 1:]>1] = 1\n",
        "            x[x<0] = 0\n",
        "            image = cv2.cvtColor(x, cv2.COLOR_HSV2RGB) # numpy array, 0 to 1\n",
        "\n",
        "            image = Image.fromarray((image * 255).astype(np.uint8))\n",
        "            # 将图片进行放置，分别对应四张分割图片的位置\n",
        "            dx = place_x[index]\n",
        "            dy = place_y[index]\n",
        "            new_image = Image.new('RGB', (w, h),\n",
        "                                  (np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)))\n",
        "            new_image.paste(image, (dx, dy))\n",
        "            image_data = np.array(new_image)\n",
        "\n",
        "            index = index + 1\n",
        "            box_data = []\n",
        "            # 对box进行重新处理\n",
        "            if len(box) > 0:\n",
        "                np.random.shuffle(box)\n",
        "                box[:, [0, 2]] = box[:, [0, 2]] * nw / iw + dx\n",
        "                box[:, [1, 3]] = box[:, [1, 3]] * nh / ih + dy\n",
        "                box[:, 0:2][box[:, 0:2] < 0] = 0\n",
        "                box[:, 2][box[:, 2] > w] = w\n",
        "                box[:, 3][box[:, 3] > h] = h\n",
        "                box_w = box[:, 2] - box[:, 0]\n",
        "                box_h = box[:, 3] - box[:, 1]\n",
        "                box = box[np.logical_and(box_w > 1, box_h > 1)]\n",
        "                box_data = np.zeros((len(box), 5))\n",
        "                box_data[:len(box)] = box\n",
        "\n",
        "            image_datas.append(image_data)\n",
        "            box_datas.append(box_data)\n",
        "\n",
        "        # 将图片分割，放在一起\n",
        "        cutx = np.random.randint(int(w * min_offset_x), int(w * (1 - min_offset_x)))\n",
        "        cuty = np.random.randint(int(h * min_offset_y), int(h * (1 - min_offset_y)))\n",
        "\n",
        "        new_image = np.zeros([h, w, 3])\n",
        "        new_image[:cuty, :cutx, :] = image_datas[0][:cuty, :cutx, :]\n",
        "        new_image[cuty:, :cutx, :] = image_datas[1][cuty:, :cutx, :]\n",
        "        new_image[cuty:, cutx:, :] = image_datas[2][cuty:, cutx:, :]\n",
        "        new_image[:cuty, cutx:, :] = image_datas[3][:cuty, cutx:, :]\n",
        "\n",
        "        # 对框进行进一步的处理\n",
        "        new_boxes = np.array(merge_bboxes(box_datas, cutx, cuty))\n",
        "\n",
        "        if len(new_boxes) == 0:\n",
        "            return new_image, []\n",
        "        if (new_boxes[:, :4] > 0).any():\n",
        "            return new_image, new_boxes\n",
        "        else:\n",
        "            return new_image, []\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        lines = self.train_lines\n",
        "        line = []\n",
        "        box_info = self.box_info\n",
        "        n = self.train_batches\n",
        "        for j in range(0, len(lines)):\n",
        "          sub_lines = []\n",
        "          sub_box_info = box_info.loc[box_info[\"img_id\"] == lines[j],]\n",
        "          sub_lines.append(self.path + lines[j])\n",
        "          for i in range(0, len(sub_box_info)):\n",
        "            X = str([sub_box_info.iloc[i,1], sub_box_info.iloc[i,4], sub_box_info.iloc[i,2], sub_box_info.iloc[i,3], sub_box_info.iloc[i,0]]).strip('[]')\n",
        "            sub_lines.append(X)\n",
        "          line.append(sub_lines)\n",
        "        index = index % n\n",
        "\n",
        "        if self.mosaic:\n",
        "            if self.flag and (index + 4) < n:\n",
        "                img, y = self.get_random_data_with_Mosaic(line[index:index + 4], self.image_size[0:2])\n",
        "            else:\n",
        "                img, y = self.get_random_data(line[index], self.image_size[0:2])\n",
        "            self.flag = bool(1-self.flag)\n",
        "        else:\n",
        "            img, y = self.get_random_data(line[index], self.image_size[0:2])\n",
        "\n",
        "        if len(y) != 0:\n",
        "            # 从坐标转换成0~1的百分比\n",
        "            boxes = np.array(y[:, :4], dtype=np.float32)\n",
        "            boxes[:, 0] = boxes[:, 0] / self.image_size[1]\n",
        "            boxes[:, 1] = boxes[:, 1] / self.image_size[0]\n",
        "            boxes[:, 2] = boxes[:, 2] / self.image_size[1]\n",
        "            boxes[:, 3] = boxes[:, 3] / self.image_size[0]\n",
        "\n",
        "            boxes = np.maximum(np.minimum(boxes, 1), 0)\n",
        "            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
        "            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
        "\n",
        "            boxes[:, 0] = boxes[:, 0] + boxes[:, 2] / 2\n",
        "            boxes[:, 1] = boxes[:, 1] + boxes[:, 3] / 2\n",
        "            y = np.concatenate([boxes, y[:, -1:]], axis=-1)\n",
        "\n",
        "        img = np.array(img, dtype=np.float32)\n",
        "\n",
        "        tmp_inp = np.transpose(img / 255.0, (2, 0, 1))\n",
        "        tmp_targets = np.array(y, dtype=np.float32)\n",
        "        return tmp_inp, tmp_targets\n",
        "\n",
        "\n",
        "# DataLoader中collate_fn使用\n",
        "def yolo_dataset_collate(batch):\n",
        "    images = []\n",
        "    bboxes = []\n",
        "    for img, box in batch:\n",
        "        images.append(img)\n",
        "        bboxes.append(box)\n",
        "    images = np.array(images)\n",
        "    return images, bboxes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6tLBG-QMpPrX"
      },
      "source": [
        "def fit_one_epoch(net,yolo_losses,epoch,epoch_size,epoch_size_val,gen,genval,Epoch,cuda):\n",
        "    total_loss = 0\n",
        "    val_loss = 0\n",
        "    start_time = time.time()\n",
        "    with tqdm(total=epoch_size,desc=f'Epoch {epoch + 1}/{Epoch}',postfix=dict,mininterval=0.3) as pbar:\n",
        "        for iteration, batch in enumerate(gen):\n",
        "            if iteration >= epoch_size:\n",
        "                break\n",
        "            images, targets = batch[0], batch[1]\n",
        "            with torch.no_grad():\n",
        "                if cuda:\n",
        "                    images = Variable(torch.from_numpy(images).type(torch.FloatTensor)).cuda()\n",
        "                    targets = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets]\n",
        "                else:\n",
        "                    images = Variable(torch.from_numpy(images).type(torch.FloatTensor))\n",
        "                    targets = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            losses = []\n",
        "            for i in range(3):\n",
        "                loss_item = yolo_losses[i](outputs[i], targets)\n",
        "                losses.append(loss_item[0])\n",
        "            loss = sum(losses)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss\n",
        "            waste_time = time.time() - start_time\n",
        "            \n",
        "            pbar.set_postfix(**{'total_loss': total_loss.item() / (iteration + 1), \n",
        "                                'lr'        : get_lr(optimizer),\n",
        "                                'step/s'    : waste_time})\n",
        "            pbar.update(1)\n",
        "            start_time = time.time()\n",
        "    net.eval()\n",
        "    print('Start Validation')\n",
        "    with tqdm(total=epoch_size_val, desc=f'Epoch {epoch + 1}/{Epoch}',postfix=dict,mininterval=0.3) as pbar:\n",
        "        for iteration, batch in enumerate(genval):\n",
        "            if iteration >= epoch_size_val:\n",
        "                break\n",
        "            images_val, targets_val = batch[0], batch[1]\n",
        "            with torch.no_grad():\n",
        "                if cuda:\n",
        "                    images_val = Variable(torch.from_numpy(images_val).type(torch.FloatTensor)).cuda()\n",
        "                    targets_val = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets_val]\n",
        "                else:\n",
        "                    images_val = Variable(torch.from_numpy(images_val).type(torch.FloatTensor))\n",
        "                    targets_val = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets_val]\n",
        "                optimizer.zero_grad()\n",
        "                outputs = net(images_val)\n",
        "                losses = []\n",
        "                for i in range(3):\n",
        "                    loss_item = yolo_losses[i](outputs[i], targets_val)\n",
        "                    losses.append(loss_item[0])\n",
        "                loss = sum(losses)\n",
        "                val_loss += loss\n",
        "            pbar.set_postfix(**{'total_loss': val_loss.item() / (iteration + 1)})\n",
        "            pbar.update(1)\n",
        "    net.train()\n",
        "    print('Finish Validation')\n",
        "    print('Epoch:'+ str(epoch+1) + '/' + str(Epoch))\n",
        "    print('Total Loss: %.4f || Val Loss: %.4f ' % (total_loss/(epoch_size+1),val_loss/(epoch_size_val+1)))\n",
        "\n",
        "    print('Saving state, iter:', str(epoch+1))\n",
        "    torch.save(model.state_dict(), 'Epoch%d-Total_Loss%.4f-Val_Loss%.4f.pth'%((epoch+1),total_loss/(epoch_size+1),val_loss/(epoch_size_val+1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Wdr7m3H2pVI_"
      },
      "source": [
        "if True:\n",
        "    lr = 1e-3\n",
        "    Batch_size = 4\n",
        "    Init_Epoch = 0\n",
        "    Freeze_Epoch = 50\n",
        "    \n",
        "    optimizer = optim.Adam(net.parameters(),lr,weight_decay=5e-4)\n",
        "    if Cosine_lr:\n",
        "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
        "    else:\n",
        "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer,step_size=1,gamma=0.95)\n",
        "\n",
        "    if Use_Data_Loader:\n",
        "        train_dataset = YoloDataset(box_info = box_info, train_lines = img_ids[:num_train], path = img_path, image_size = (input_shape[0], input_shape[1]), mosaic=mosaic)\n",
        "        val_dataset = YoloDataset(box_info = box_info, train_lines = img_ids[num_train:], path = img_path, image_size= (input_shape[0], input_shape[1]), mosaic=False)\n",
        "        gen = DataLoader(train_dataset, shuffle=True, batch_size=Batch_size, num_workers=4, pin_memory=True,\n",
        "                                drop_last=True, collate_fn=yolo_dataset_collate)\n",
        "        gen_val = DataLoader(val_dataset, shuffle=True, batch_size=Batch_size, num_workers=4,pin_memory=True, \n",
        "                                drop_last=True, collate_fn=yolo_dataset_collate)\n",
        "    else:\n",
        "        gen = Generator(Batch_size, box_info = box_info, train_lines = liimg_idsnes[:num_train], path = img_path,\n",
        "                        image_size = (input_shape[0], input_shape[1])).generate(mosaic = mosaic)\n",
        "        gen_val = Generator(Batch_size, box_info = box_info, train_lines = img_ids[num_train:], path = img_path,\n",
        "                        image_size = (input_shape[0], input_shape[1])).generate(mosaic = False)\n",
        "\n",
        "    epoch_size = max(1, num_train//Batch_size)\n",
        "    epoch_size_val = num_val//Batch_size\n",
        "    #------------------------------------#\n",
        "    #   冻结一定部分训练\n",
        "    #------------------------------------#\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    for epoch in range(Init_Epoch,Freeze_Epoch):\n",
        "        fit_one_epoch(net,yolo_losses,epoch,epoch_size,epoch_size_val,gen,gen_val,Freeze_Epoch,Cuda)\n",
        "        lr_scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
